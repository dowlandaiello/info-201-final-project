---
title: "Analysis: Impact of Public Opinion on Immigration Policy in the United States"
author: "Dowland Aiello, Roy Lin, Winston Qi"
date: "2025-06-08"
output: html_document
---

```{r setup ,include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. Abstract

_Note: all files from this project are available on [GitHub](https://github.com/dowlandaiello/info-201-final-project)._

Herein, we investigate the relationship between public opinion on immigration and U.S. immigration policy from 2004 to 2024. We establish Google trends search interest as a proxy measure of public opinion. We decompose the primary research question into 3 sub-questions measuring immigration policy by election outcomes, deporations, and encounters at the border. We conclude that there appears to be correlation between Google trends search interest and election outcomes. However, the relationship between search interest and arrests/deportations remains elusive.

# 2. Introduction

Immigration has become an increasingly discussed issue in the United States. For the 2024 election cycle, immigration emerged as a driving factor resulting in the loss of the Democratic party. 

While popular discourse has made clear that the American voting public is skeptical of the government's approach towards immigration policy, it is unclear whether this skepticisim is empirically well-founded. Furthermore, the direct impact of voting on immigration policy is unclear. We establish three research questions in this paper to analyze how public opinion towards immigration has shaped policy in the US:

1. How is the change in public sentiment towards immigration (measured via Google trends interest) correlated with Presidential election results?
2. How are presidential election results correlated with immigration policy (measured via deporations and encounters at the border)?
3. How has public sentiment towards immigration in the US affected immigration policy over time (measured via deporations and encounters at the border)?

In the modern internet-driven media ecosystem, Google trends may serve as a valuable measure of public sentiment towards immigration in the US. Though not an actual measure of opinion, these data could provide important geographical context not otherwise available with existing measures (e.g., public opinion polls).

By answering these questions, we hope to provide insight to members of the media, voters, and policy-makers into the interplay between public opinion on immigration and policy.

# 3. Data Source

We make use of three datasets in this paper.

## 3.1 [Google trends data for "immigration"](https://trends.google.com/trends/)

This dataset is available under Google's terms of service. Google Trends provides downloadable historical data by geographical region. However, it does not provide historical data for selections of multiple regions. We opted to download nation-wide county-level search interest averagese for various periods of 4 years corresponding to election cycles.

## 3.2 [Harvard county-level election data](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VOQCHQ)

This dataset uses a CC0 1.0 Universal license. This license is very permissible. The dataset contains county-level election results by year, office, and party in the United States.

## 3.3 [Border encounters and deportation data](https://deportationdata.org/data.html)

This dataset also uses a CC0 1.0 Universal license. This license is very permissible. This dataset contains individual-level arrests and deportations by ICE and Border Patrol in the United States.

All data were collected by Dowland Aiello.

# 4. Data

## 4.1 Google Trends Data

After merging and cleaning, this dataset contains 2,730 rows and 4 columns. Each row includes average search interest for "immigration" ("query_incidence") ranked from 0 - 100 over an indicated timeframe ("daterange") for a given county ("DMA").

* Date ranges are represented as strings in the form "%YY-%YY".
* Average query incidence is represented by an integer
* County names are strings containing the name of the county and its state (in the form "NY", "CA").

`NA` values are encoded explicitly as the value `NA`.

## 4.2 County-level Election Data

In its raw form, this dataset contains 72,618 rows and 13 columns. Each row represents the number of votes for a candidate in a given county running under a specified party for a specified office in a specified year. Relevant columns include:

* `year` - represented by a 4-digit integer
* `state` - fully expanded string of the form ("ALABAMA")
* `county_name` - shortened uppercase county-name in the form ("AAUTAUGA")
* `office` - string of the form "US PRESIDENT"
* `party` - string of the form "REPUBLICAN"
* `candidatevotes` - integer
* `totalvotes` - integer

`NA` values are encoded explicitly as the value `NA`.

## 4.3 Border encounters and deportation data

This dataset is extremely large and requires significant cleaning. Even after cleaning, a table with multiple hundreds of thousands of lines is produced. To enable file-sharing on GitHub, we separate this table into multiple compressed `.csv.bz` files with a maximum row count of 100,000. Each table contains 30 columns. Relevant columns include:

* `Port of Departure` - string indicating which city, state they were deported in. This will be relevant to our analysis and worth merging with county names in the electoral and trends datasets.

The border encounters dataset was similarly extraordinarily large. We break the table up into multiple tables with a maximum of 10,000 rows. Each table contains 9 columns. Relevant columns include:

* `FY` - year of observation, formatted like such: "FY%YYYY". This will be useful to calculate the change in border apprehensions over time.

`NA` values are encoded explicitly as expected in both datasets.

# 5. Method

## 5.1 Data Cleaning

See the [`scripts/`](https://github.com/dowlandaiello/info-201-final-project/tree/master/scripts) folder for utilities we wrote to clean our data:

1. All Google trends data files were originally named "geoMap*.csv." We renamed each file to include a timestamp ("query_immigration_metro_%YY-%YY") derived from timestamps in the column names of the files. We then merged all timeframes into a single table by deriving a "daterange" column from the file's name.
2. Harvard election data was filtered to include only rows where `office == "US PRESIDENT"`. No `NA` values were present in the relevant vote count and office columns. The data were fairly clean.
3. Apprehensions data were originally provided in `.xlsx` excel format. Furthermore, each table was multiple hundreds of thousands of rows long. We break each table into multiple compressed `.csv.bz` files in order to upload each table to GitHub. We elaborate more on data cleaning for this table in the relevant sections. These data span multiple hundreds of thousands of lines. We defer to the relevant subsection of this section for more information.

## 5.2 Research Question 1:

Herein, we explore the relationship between Google search query incidence for "immigration" and the electoral swing in the presidential election in several election cycles from 2004 - 2020. We aim to determine whether there is any correlation between search interest for "immigration" and the electoral swing. We utilize a county-level timestamped dataset of average Google Trends search query interest over indicated timeframes. We also make use of Harvard's county-level election results dataset.


```{r}
library(dplyr)
library(purrr)
library(tidyr)
library(stringr)

trendsdf <- read.csv("../../data_cleaned/google_trends/summarized.csv")
trendsdf %>% head(5)
```

### 5.2.1 Electoral Swing

#### 5.2.1.1 Data Overview

Here is an overview of the dataset:

```{r}
electiondf <- read.csv("../../data_cleaned/harvard_election/countypres_2000-2020.csv")
electiondf %>% sample_n(10)
```

#### 5.2.1.2 Data Cleaning

We can gather all votes per county by pivoting the data.

```{r}
votestimeframe <- electiondf %>%
  select(year, state, county_name, party, office, candidatevotes, totalvotes) %>%
  # Select only republican so that further analysis can have red/blue as meaningful colors
  filter(office == "US PRESIDENT") %>%
  # Collapse votes in year n, n1 into columns n, n1
  group_by(year, state, county_name, office, party) %>%
  summarise(year, state, county_name, candidatevotes) %>%
  ungroup() %>%
  distinct(party, state, county_name, year, .keep_all = TRUE) %>%
  select(party, state, county_name, year, candidatevotes) %>%
  pivot_wider(id_cols = c(state, county_name), names_from = c(party, year), values_from = c(candidatevotes))

votestimeframe %>% head(10)
```

#### 5.2.1.3 Swing Calculation

We can then calculate the swing like such:

```{r}
votestimeframe %>%
    group_by(state, county_name) %>%
    summarise(swing = .data[["REPUBLICAN_2012"]] / (.data[["REPUBLICAN_2012"]] + .data[["DEMOCRAT_2012"]]) - .data[["REPUBLICAN_2004"]] / (.data[["REPUBLICAN_2004"]] + .data[["DEMOCRAT_2004"]])) %>%
    head(10)
```

#### 5.2.1.4 Change in Google Trends Interest Over a Timeframe

Now, we calculate the change in average query incidence from one timeframe to the next. We use a similar pivoting method to get (date ranges, queyr_incidence) as columns.

```{r}
trendsdf %>%
  pivot_wider(id_cols = c(DMA), names_from = daterange, values_from = query_incidence, values_fn = max) %>%
  (\(df) df %>% mutate("change_04-12" = df[["08-12"]] - df[["04-08"]])) %>%
  head(10)
```

We define a function which calculates the change over a given time period for all regions.

```{r}
change_time_period <- function(date1, date2) {
  trendsdf %>%
    pivot_wider(id_cols = c(DMA), names_from = daterange, values_from = query_incidence, values_fn = max) %>%
    mutate("change_query_incidence" = .data[[date1]] - .data[[date2]])
}

change_time_period("08-12", "04-08") %>% head(10)
change_time_period("16-17", "19-20") %>% head(10)
```

#### 5.2.2.5 Map: Query Incidence vs Electoral Swing (2004 election to 2012 election)

Our visualization of electoral swing uses a diverging color scale indicating how Republican or Democrat a county became. We pair this color visualization with scaling to indicate the query incidence in a given county.

We first match counties from the Google trends dataset to the electoral dataset to create the visualization. We do so by checking for counties in the election data which are substrings of the Google trends DMA column.

```{r}
library(fuzzyjoin)

interest_swing_08_12 <- change_time_period("08-12", "04-08") %>% mutate(county = toupper(DMA)) %>% select(county, change_query_incidence)
swing_county <- votestimeframe %>%
    group_by(state, county_name) %>%
    summarise(swing = .data[["REPUBLICAN_2012"]] / (.data[["REPUBLICAN_2012"]] + .data[["DEMOCRAT_2012"]]) - .data[["REPUBLICAN_2004"]] / (.data[["REPUBLICAN_2004"]] + .data[["DEMOCRAT_2004"]])) %>%
    mutate(county = county_name) %>%
    select(county, swing)

regex_inner_join(interest_swing_08_12, swing_county, by = "county") %>% head(10)
```

In order to match county names to locations on a map, we geocode each row using the `ggmap` library. Note that we cache geocoding results in an auxiliary `.csv` file.

```{r}
library(ggmap)

#register_google(key = Sys.getenv("GOOGLE_API_KEY"), write = FALSE)

#with_lat_long <- regex_inner_join(interest_swing_08_12, swing_county, by = "county") %>%
    #select(county = county.y, swing, change_query_incidence, state) %>%
    #(\(df) df %>% mutate(lat_long = geocode(output = "latlon", location = paste(df$county, ", ", df$state), method = "census")))

#with_lat_long %>% write.csv("../../data_cleaned/swing_interest_vs_electoral_04_12_lat_long.csv")
#with_lat_long %>% head(10)

with_lat_long <- read.csv("../../data_cleaned/swing_interest_vs_electoral_04_12_lat_long.csv") %>%
    mutate(lat = lat_long.lat, long = lat_long.lon) %>%
    arrange(lat, long)
with_corr <- with_lat_long %>%
    filter(!is.na(change_query_incidence) & !is.na(swing))

with_corr %>% select(change_query_incidence, swing, lat, long) %>% head(10)
```

Using the geocoded data, we can generate a map. We use the tidyverse `maps` library to create a map of the United States. We use a diverging color scale to indicate that 0.0 has a meaningful value (no swing). We indicate relative search query incidence by scaling the area of points representing counties.

```{r, fig.height = 12, fig.width = 16.8}
library(maps)
library(ggplot2)
library(scales)

plot <- ggplot(data = map_data("state") %>% filter(long > -140)) +
  geom_polygon(aes(x = long, y = lat, group = group), color = "white") +
  geom_point(data = with_corr %>% filter(long > -140), aes(x = long, y = lat, color = as.numeric(swing), alpha = as.numeric(change_query_incidence), size = as.numeric(change_query_incidence))) +
  scale_colour_gradient2(low = "blue", high = "red", mid = "gray", midpoint = 0) +
  labs(
    title = "Change in Search Interest for \"Immigration\" vs Electoral Swing from 2004 - 2012",
    color = "Swing in Election Results (Red = Became More Republican)",
    size = "Change in Search Interest for \"Immigration\"",
  ) +
  guides(alpha = "none") +
  scale_alpha(range = c(0.05, 1), limits = c(-30, 20)) +
  scale_size_binned(n.breaks = 5, range = c(0.25, 5), limits = c(-50, 100)) +
  theme(text = element_text(size = 13), legend.text = element_text(size = 8), legend.position = "bottom")

ggsave("election_04_to_2012_heat_map_query_change_election_result.png", bg = "white")

plot
```


#### 5.2.2.6 Comparison to 2008 - 2020 change

Here, we generate the same map, but for elections from 2008 - 2020.

```{r}
library(fuzzyjoin)

interest_swing_08_12_16_20 <- change_time_period("08-12", "16-20") %>% mutate(county = toupper(DMA)) %>% select(county, change_query_incidence)
swing_county <- votestimeframe %>%
    group_by(state, county_name) %>%
    summarise(swing = .data[["REPUBLICAN_2016"]] / (.data[["REPUBLICAN_2016"]] + .data[["DEMOCRAT_2016"]]) - .data[["REPUBLICAN_2008"]] / (.data[["REPUBLICAN_2008"]] + .data[["DEMOCRAT_2008"]])) %>%
    mutate(county = county_name) %>%
    select(county, swing)

regex_inner_join(interest_swing_08_12_16_20, swing_county, by = "county") %>% head(10)
```

```{r}
library(ggmap)

#register_google(key = Sys.getenv("GOOGLE_API_KEY"), write = FALSE)
#with_lat_long <- regex_inner_join(interest_swing_08_12_16_20, swing_county, by = "county") %>%
    #select(county = county.y, swing, change_query_incidence, state) %>%
    #(\(df) df %>% mutate(lat_long = geocode(output = "latlon", location = paste(df$county, ", ", df$state), method = "census")))

#with_lat_long %>% write.csv("../../data_cleaned/swing_interest_vs_electoral_08_20_lat_long.csv")
#with_lat_long %>% head(10)
```

```{r, fig.height = 12, fig.width = 16.8}
library(maps)
library(ggplot2)
library(purrr)
library(scales)

with_lat_long.2 <- read.csv("../../data_cleaned/swing_interest_vs_electoral_08_20_lat_long.csv") %>%
    mutate(lat = lat_long.lat, long = lat_long.lon) %>%
    arrange(lat, long)
with_corr.2 <- with_lat_long.2 %>%
    filter(!is.na(change_query_incidence) & !is.na(swing))

with_corr.2 %>% select(change_query_incidence, swing, lat, long) %>% head(10)

plot <- ggplot(data = map_data("state") %>% filter(long > -140)) +
  geom_polygon(aes(x = long, y = lat, group = group), color = "white") +
  geom_point(data = with_corr.2 %>% filter(long > -140), aes(x = long, y = lat, color = as.numeric(swing), alpha = as.numeric(change_query_incidence), size = as.numeric(change_query_incidence))) +
  scale_colour_gradient2(low = "blue", high = "red", mid = "gray", midpoint = 0) +
  labs(
    title = "Change in Search Interest for \"Immigration\" vs Electoral Swing from 2008 - 2016",
    color = "Swing in Election Results (Red = Became More Republican)",
    size = "Change in Search Interest for \"Immigration\"",
    ) +
  guides(alpha = "none") +
  scale_alpha(range = c(0.05, 1), limits = c(-30, 20)) +
  scale_size_binned(n.breaks = 5, range = c(0.25, 5), limits = c(-50, 100)) +
  theme(text = element_text(size = 13), legend.text = element_text(size = 8), legend.position = "bottom")


ggsave("election_08_to_2020_heat_map_query_change_election_result.png", bg = "white")

plot
```

#### 5.2.2.7 Comparison to 2016 - 2020 Change

Here, we generate the same heatmap, but for elections from 2016 - 2020.

```{r}
library(fuzzyjoin)

interest_swing_16_20 <- change_time_period("16-17", "19-20") %>% mutate(county = toupper(DMA)) %>% select(county, change_query_incidence)
swing_county <- votestimeframe %>%
    group_by(state, county_name) %>%
    summarise(swing = .data[["REPUBLICAN_2020"]] / (.data[["REPUBLICAN_2020"]] + .data[["DEMOCRAT_2020"]]) - .data[["REPUBLICAN_2016"]] / (.data[["REPUBLICAN_2016"]] + .data[["DEMOCRAT_2016"]])) %>%
    mutate(county = county_name) %>%
    select(county, swing)

regex_inner_join(interest_swing_16_20, swing_county, by = "county") %>% filter(!is.na(change_query_incidence)) %>% head(10)
```

```{r}
library(ggmap)

#register_google(key = Sys.getenv("GOOGLE_API_KEY"), write = FALSE)
#with_lat_long <- regex_inner_join(interest_swing_16_20, swing_county, by = "county") %>%
    #select(county = county.y, swing, change_query_incidence, state) %>%
    #(\(df) df %>% mutate(lat_long = geocode(output = "latlon", location = paste(df$county, ", ", df$state), method = "census")))

#with_lat_long %>% write.csv("../../data_cleaned/swing_interest_vs_electoral_16-20_lat_long.csv")
#with_lat_long %>% head(10)
```

```{r, fig.height = 12, fig.width = 16.8}
library(maps)
library(ggplot2)
library(purrr)
library(scales)

with_lat_long.2 <- read.csv("../../data_cleaned/swing_interest_vs_electoral_16-20_lat_long.csv") %>%
    mutate(lat = lat_long.lat, long = lat_long.lon) %>%
    arrange(lat, long)
with_corr.2 <- with_lat_long.2 %>%
    filter(!is.na(change_query_incidence) & !is.na(swing))

with_corr.2 %>% select(change_query_incidence, swing, lat, long) %>% head(10)

plot <- ggplot(data = map_data("state") %>% filter(long > -140)) +
  geom_polygon(aes(x = long, y = lat, group = group), color = "white") +
  geom_point(data = with_corr.2 %>% filter(long > -140), aes(x = long, y = lat, color = as.numeric(swing), alpha = as.numeric(change_query_incidence), size = as.numeric(change_query_incidence))) +
  scale_colour_gradient2(low = "blue", high = "red", mid = "gray", midpoint = 0) +
  labs(
    title = "Change in Search Interest for \"Immigration\" vs Electoral Swing from 2016 - 2020",
    color = "Swing in Election Results (Red = Became More Republican)",
    size = "Change in Search Interest for \"Immigration\"",
    ) +
  guides(alpha = "none") +
  scale_alpha(range = c(0.05, 1), limits = c(-30, 20)) +
  scale_size_binned(n.breaks = 5, range = c(0.25, 5), limits = c(-50, 100)) +
  theme(text = element_text(size = 13), legend.text = element_text(size = 8), legend.position = "bottom")


ggsave("election_16_to_2020_heat_map_query_change_election_result.png", bg = "white")

plot
```

#### 5.2.2.8 Observations

Notable in the above maps are:
- Swing states
- Polarization of elections over time

However, it is relatively difficult to interpret search query incidence in any meaningful way.

#### 5.2.2.9 Alternative Visualization: Scatter Plot w/ Linear Regression

In order to compare the relationship between query incidence and election results more explicitly, we generate a scatter plot of counties' electoral swing and search query incidence in the same election cycles.

```{r}
tf.1 <- read.csv("../../data_cleaned/swing_interest_vs_electoral_04_12_lat_long.csv") %>%
    mutate(group = "04-12")
tf.2 <- read.csv("../../data_cleaned/swing_interest_vs_electoral_08_20_lat_long.csv") %>%
    mutate(group = "08-20")
tf.3 <- read.csv("../../data_cleaned/swing_interest_vs_electoral_16-20_lat_long.csv") %>%
    mutate(group = "16-20")

joined <- rbind(tf.1, tf.2, tf.3)

joined %>%
    group_by(group) %>%
    ggplot(aes(x = change_query_incidence, y = swing, color = factor(group))) +
    labs(
        title = "Change in Search Interest for \"Immigration\" vs Electoral Swing",
        color  = "Date Range (years)",
        x  = "Change in Search Interest for \"Immigration\"",
        y = "Electoral Swing"
    ) +
    geom_point(size = 2, alpha = 0.5) +
    geom_smooth(method = lm)
```

This visualization is significantly easier to interpret. We note that there is **virtually zero** correlation between search query incidence and election results in the 2004 - 2012 election cycle. However, there was some correlation in the 2008 - 2016 cycle, and slightly more in the 2016 - 2020 election cycle (slightly steeper slope). Thus, we can conclude that the correlation between search interest for immigration and the electoral swing has grown stronger over time.




## 5.3 Research Question 2:

Aim to explore the relationships between apprehensions at the border, deportations, and election results (through total and difference in votes between the Republican and Democrat parties). Find correlations between election results and immigration policy (measured through annual apprehensions and deportations)

## 5.3.1 Method
In general, to explore the extent of my question, I:
- Cleaned all datasets for consistent time formatting, variable naming, and missing data.
- Transformed the election results into a long format that included total votes by party and year.
- Aggregated apprehension and deportation datasets into a by year and total votes format for easier comparison.
- Merged the datasets on year to compare political outcomes with enforcement levels.

I created 2 main new variables: 
- party_diff: Numeric difference between Republican and Democratic votes.
- border_state: A categorical variable indicating whether a state borders Mexico.

TODO:
Some of the challenged I faced during my manipulation and analysis were deciding what formats to use, 
Analysis of results is provided with graphs in Results section below.

### 5.3.1.1 Date Separation Function
Created a function to separate the year column of a dataframe into a date format when needed, later discarded other newly created date columns for just year, as I wanted to capture larger trends by year for the bigger picture of periods between elections rather than a day by day/month by month basis.
```{r , message = FALSE}
date_sep <- function(data, date_col) {
  mutate(data, date = as_date({{date_col}}, format = "%m/%d/%Y")) %>%
  mutate(year = as.numeric(format(date, format = "%Y")),
         month = as.numeric(format(date, format = "%m")),
         day = as.numeric(format(date, format = "%d"))) %>% 
    select(year, month, day, date) %>% 
    na.omit()
}
```

### 5.3.1.2 Election Results Filtering  

Checked to make sure that there wasn't NA values or other substutionary values in the total votes, then summarized the Democrat and Republican total votes by year and put them into one dataframe. Only concerned with Republicans and Democrats, as they are the 2 main parties that win US elections and the portion of votes from other parties are not significant enough to affect any election results.
Pivoted to wide to make the voting totals per year by party easier to interpret visually, then included a voting difference variable. The aggregate total votes for each party by year helps quickly see and compare the total amount of votes that each party got, while the difference helps see the general party voting trends in the United States and which party is winning the popular vote.
```{r, message=FALSE}
range(election_results$candidatevotes)

dem_votes <- election_results %>% 
  select(year, party, candidatevotes) %>% 
  na.omit() %>% 
  filter(party %in% "DEMOCRAT") %>% 
  group_by(year, party) %>% 
  summarize(tot_votes = sum(candidatevotes))
head(dem_votes)

rep_votes <- election_results %>% 
  select(year, party, candidatevotes) %>% 
  na.omit() %>% 
  filter(party %in% "REPUBLICAN") %>% 
  group_by(year, party) %>% 
  summarize(tot_votes = sum(candidatevotes))
head(rep_votes)

total_votes_by_yr <- rbind(dem_votes, rep_votes)
head(total_votes_by_yr)

wide_votes <- total_votes_by_yr %>% 
  pivot_wider(id_cols = year, names_from = party, values_from = tot_votes)
head(wide_votes)

vote_diff_by_yr <- wide_votes %>% 
  mutate("Vote Difference (Republican minus Democrat)" = REPUBLICAN - DEMOCRAT)
head(vote_diff_by_yr)
```


### 5.3.1.3 Border Status Differentiation

Used cleaning methods of above section except creating new categorical variables/columns of border status, border state, etc. to determine a state' status of being on the border of the United States or not and differentiating the types of votes through border and political party categories. These distinctions will help in answering one of the sub questions of whether people in border states will be more likely to vote Republican for their immigration policies due to immigration being a more tangible and closer issue to them - through comparing the voting trends of border and non-border states.
``` {r , message = FALSE}
border_states <- c("MAINE", "NEW HAMPSHIRE", "VERMONT", "NEW YORK", "PENNSYLVANIA", "OHIO", "MICHIGAN", "MINNESOTA", "NORTH DAKOTA", "MONTANA", "IDAHO", "WASHINGTON", "ALASKA", "CALIFORNIA", "NEW MEXICO", "ARIZONA", "TEXAS")

bor_status <- election_results %>% 
  mutate(border_state = state %in% border_states) 
bor_status

dem_bor_votes <- bor_status %>% 
  select(year, party, candidatevotes, border_state) %>% 
  na.omit() %>% 
  filter(party %in% "DEMOCRAT") %>% 
  group_by(year, party, border_state) %>% 
  summarize(tot_votes = sum(candidatevotes))
dem_bor_votes

rep_bor_votes <- bor_status %>% 
  select(year, party, candidatevotes, border_state) %>% 
  na.omit() %>% 
  filter(party %in% "REPUBLICAN") %>% 
  group_by(year, party, border_state) %>% 
  summarize(tot_votes = sum(candidatevotes))
rep_bor_votes

total_bor_votes_by_yr <- rbind(dem_bor_votes, rep_bor_votes) 
total_bor_votes_by_yr

wide_bor_votes <- total_bor_votes_by_yr %>% 
  pivot_wider(id_cols = year, names_from = c(party, border_state), values_from = tot_votes)
colnames(wide_bor_votes)[colnames(wide_bor_votes) == "DEMOCRAT_FALSE"] <- "Non-Border: Democrat"
colnames(wide_bor_votes)[colnames(wide_bor_votes) == "DEMOCRAT_TRUE"] <- "Border: Democrat"
colnames(wide_bor_votes)[colnames(wide_bor_votes) == "REPUBLICAN_FALSE"] <- "Non-Border: Republican"
colnames(wide_bor_votes)[colnames(wide_bor_votes) == "REPUBLICAN_TRUE"] <- "Border: Republican"
wide_bor_votes <- wide_bor_votes %>% 
  mutate("Border Vote Difference" = `Border: Republican` -`Border: Democrat`) %>% 
  mutate("Non-Border Vote Difference" = `Non-Border: Republican` - `Non-Border: Democrat`) 
wide_bor_votes

long_df_bor <- wide_bor_votes %>% 
  pivot_longer(cols = c("Non-Border: Democrat", "Border: Democrat",
                        "Non-Border: Republican", "Border: Republican",
                        "Border Vote Difference", "Non-Border Vote Difference"),
                 names_to = "Number of State Votes:", names_transform = list(n = as.integer),
                 values_to = "number") %>% 
  na.omit()

long_df_bor
```


### 5.3.1.4 Deportations Filtering and Merging

Did not use a loop or other method to group datasets for filtering and date separation before merging as the file variables and their order were inconsistent between datasets. Selected only the departure dates of for consistency and the dates for which immigrants were deported. Discarded other variables like Birth Country or Citizenship Country of immigrants. Such variables were originally planned for usage and analysis but later on I decided that they didn't help answer my research question of how election results affected immigration policy as much as I initially thought, instead opting to focus on the total number of deportations that happen in a given year to track the impact of immigration policies. Used the date_sep function to filter out the dates for each of the deportations in the datasets, then binded them together into a total deportations dataset, using sample_n and head to check that it is good. Discarded the complete date, month, and day portions created by the date_sep function to keep the year, and counted the # of rows each year had. There were some breaks in the years (e.g missing 2017 and 2020-2021) due to no datasets for those years being present in the source that pertained to the same category, but decided to continue general trends in deportations can still be seen with the years that are available.
```{r , message = FALSE}
totalice_yr11_12 <- ice_rem11_12 %>% 
  select(...2) %>%
  date_sep(...2)

totalice_yr13 <- ice_rem13 %>% 
  select(`ERO-LESA Statistical Tracking Unit`) %>% 
  date_sep(`ERO-LESA Statistical Tracking Unit`) 

totalice_yr14_15 <- ice_rem15 %>% 
  select(...3) %>% 
  date_sep(...3)
 
totalice_yr16_14 <- ice_rem16_14 %>% 
  select(`ERO-LESA Statistical Tracking Unit`) %>% 
  date_sep(`ERO-LESA Statistical Tracking Unit`) 

totalice_yr19_17 <- ice_rem19_17 %>% 
  select(`ERO-LESA Statistical Tracking Unit`) %>% 
  date_sep(`ERO-LESA Statistical Tracking Unit`) 

totalice_yr23_20 <- ice_rem23_22 %>% 
  select(`ERO-LESA Statistical Tracking Unit`) %>% 
  date_sep(`ERO-LESA Statistical Tracking Unit`)

totalice_by_year <- rbind(totalice_yr11_12, totalice_yr13, totalice_yr14_15, totalice_yr16_14, totalice_yr19_17, totalice_yr23_20) %>% 
  select(date, year, month, day)
totalice_by_year
head(totalice_by_year)
sample_n(totalice_by_year, 20)

icedeports_by_yr <- totalice_by_year %>% 
  select(year) %>% 
  na.omit() %>% 
  count(year)

colnames(icedeports_by_yr)[colnames(icedeports_by_yr) == "n"] <- "Deportations"
icedeports_by_yr
```


### 5.3.1.5 Apprehensions Filtering and Merging

Similarly to the above section, only selected/filtered for the year and discarded other variables/values for general yearly apprehension trends that correspond to immigration policies' impacts/enforcements. The values with year in the variable "U.S. Border Patrol Nationwide Apprehensions" did not include month, day, or time, so filtered for the years through checking for the string "FY2", combining all the cleaned datasets, then removing the "FY" suffix to leave just the year and counting up the number of apprehensions per year. 
```{r , message = FALSE}
app_00_06 <- rbind(app_2000, app_2001, app_2002 , app_2003, app_2004, app_2005, app_2006)
app_00_06 <- app_00_06 %>%
  select(`U.S. Border Patrol Nationwide Apprehensions `) %>%
  filter(str_detect(`U.S. Border Patrol Nationwide Apprehensions `, "FY2"))

app_07_15 <- rbind(app_2007, app_2008, app_2009, app_2010, app_2011, app_2012, app_2013, app_2014, app_2015)
app_07_15 <- app_07_15 %>% 
  select(`U.S. Border Patrol Nationwide Apprehensions `) %>% 
  filter(str_detect(`U.S. Border Patrol Nationwide Apprehensions `, "FY2"))

app_16_22 <- rbind(app_2016, app_2017, app_2018, app_2019, app_2020, app_2021, app_2022)
app_16_22 <- app_16_22 %>% 
  select(`U.S. Border Patrol Nationwide Apprehensions `) %>% 
  filter(str_detect(`U.S. Border Patrol Nationwide Apprehensions `, "FY2"))

totalapp_by_year <- rbind(app_00_06, app_07_15, app_16_22)

totalapp_by_year <- str_replace_all(totalapp_by_year$`U.S. Border Patrol Nationwide Apprehensions `, "[FY]", "") %>% 
  data.frame() 
colnames(totalapp_by_year)[colnames(totalapp_by_year) == "."] <- "year"

apps_by_yr <- totalapp_by_year %>% 
  select(year) %>% 
  na.omit() %>% 
  count(year) 

colnames(apps_by_yr)[colnames(apps_by_yr) == "n"] <- "Apprehensions at the Border"
apps_by_yr <- apps_by_yr %>% 
  transform(year = as.integer(year)) 

apps_by_yr
```


### 5.3.1.6 Aggregate Dataset Merging into Long Format

This code chunk is for the merging, arranging, and pivoting to long form the core and cleaned/reworked datasets for intended visual graphs and their subsequent analyses.
```{r , message = FALSE}
app_dep_votes <- rbind(wide_votes, apps_by_yr, icedeports_by_yr, vote_diff_by_yr) %>% 
  arrange(year)
app_dep_votes

longdf_A_D_V <- app_dep_votes %>% 
  pivot_longer(cols = c("DEMOCRAT", "REPUBLICAN", "Apprehensions at the Border",
                        "Deportations", "Vote Difference (Republican minus Democrat)"),
                 names_to = "Number of:", names_transform = list(n = as.integer),
                 values_to = "number") %>%
  na.omit()
longdf_A_D_V
```


## 5.3.2 Analysis

TODO:
For my analysis, I decided to first create some graphs/plots to visually analyze the data gathered before deciding on any further potential or more complex analysis methods (e.g. slopes, linear regression) were needed. If the graphs clearly show certain direction trends or , then

I mainly stuck to line graphs due to the heavily numerical aspects of my data, with the exception being the bar plot regarding the election results 


#### 5.3.2.1 Aggregate Line Graph of all Datasets

I first attempted to compare the number of deportations and apprehensions to votes by year separately, and so created two line graphs to see the general voting trends  against the immigration related data. At a glance, it seems fairly hard to distinguish any trends given the sizable numerical gap between the election results and deportations/apprehensions, with the later two seemingly having close to no fluctuations or changes in their number on the scale currently alloted in the graph by default. In fact, it seems like both look like they are extremely close to 0, which is not true at all considering the values gleaned from above. Additionally, there are several points where data cuts off, like how the election results cuts off at 2020, or how deportations has much less datapoints to go off of compared to the other data, not to mention how it has some missing years.

As such, these observations led me to break down the graphs into comparisons

```{r}
longdf_A_D_V %>% 
  filter(`Number of:`  %in% c("Deportations", "Vote Difference (Republican minus Democrat)", "REPUBLICAN", "DEMOCRAT")) %>% 
  mutate(year = as.integer(year))%>% 
  ggplot(aes(x = year, y = number, col = `Number of:`)) +
  geom_point() +
  geom_line() +
  labs(title = "Deportations and Votes, by Year")


longdf_A_D_V %>% 
  filter(`Number of:`  %in% c("Apprehensions at the Border", "Vote Difference (Republican minus Democrat)", "REPUBLICAN", "DEMOCRAT")) %>% 
  mutate(year = as.integer(year))%>% 
  ggplot(aes(x = year, y = number, col = `Number of:`)) +
  geom_point() +
  geom_line() +
  labs(title = "Apprehensions and Votes, by Year")
```

#### 5.3.2.2 Election Results (Popular Vote)

#### 5.3.2.2.1 Election Results from Total Party Candidate Votes

As can be seen, Democrats won the majority of popular votes between 2000-2020, with the Republicans only winning in 2004 over the Democrats. Initially between 2000-2004, the amount of votes between the parties are fairly close, but afterwards the Democrats maintained the lead with several millions of votes for each election.
```{r}
total_votes_by_yr %>% 
  mutate(year = as.character(year)) %>% 
  ggplot(aes(x = year, y = tot_votes)) +
  geom_col(aes(fill = party), stat = "identity", position = "dodge") +
  labs(title = "Election Results from Total Party Candidate Votes", 
       y = "Number of Candidate Votes")  +
   scale_y_continuous(name="Number of Candidate Votes", labels = comma) +
  scale_fill_manual(values = c("#03bfc4", "#f7766d"), 
                    breaks = c("DEMOCRAT", "REPUBLICAN"))
```

#### 5.3.2.2.2 Total Vote Differences (Republican - Democrat)

The line graph shows that there was an initial trend in Republican Voting like the previous barplot suggested, but that the trend flipped on its head to Democrat lead in 2008. The popular vote has maintained democrat for all but 2004, but was still overcome in 2000, 2004, and 2016, partially indicated as peaks in Republican voting during those years.

TODO: 
While not completely relevant to the topic, the trend was 
``` {r}
# Vote Difference Only
app_dep_votes %>%
  select(year, `Vote Difference (Republican minus Democrat)`) %>% 
  na.omit() %>% 
  # works, need the above 2 things to work
  ggplot(aes(x = year, y = `Vote Difference (Republican minus Democrat)`,
             color = `Vote Difference (Republican minus Democrat)`)) +
  geom_point(size = 2) +
  geom_line(aes(group=1)) + 
  geom_hline(yintercept = 0, color = "black") +
  scale_y_continuous(name="Number of Votes", labels = comma) +
  labs(title = "Voting Difference (Rep. - Dem.), by Year") +
  scale_color_gradient(labels = comma,
    low = "blue",
    high = "red")
```

#### 5.3.2.3 Apprehensions vs Deportations 

TODO:

While I did start with a plot including the voting difference with apprehensions and deportations, the data for the vote difference was not as applicable or generalizable as I thought to the data regarding immigration enforcement, as the lengths between each election year was fairly wide (being 4 years), making it hard to try and find direct correlation between the more frequently changing values of the other two. Additionally, the numerical difference was still very wide despite the reduction in scale compared to my inital graphs of all the datasets as one graph, which restricts the degree of comparisons/analysis visually.


Even when considering apprehensions, which had more years of data than deportations, it was hard to see any changes from election results reflected into apprehensions.

```{r}
longdf_A_D_V %>% 
  filter(`Number of:`  %in% c("Apprehensions at the Border",
  "Deportations", "Vote Difference (Republican minus Democrat)")) %>% 
  na.omit() %>% 
  mutate(year = as.integer(year))%>% 
  ggplot(aes(x = year, y = number, col = `Number of:`)) +
  geom_point() +
  geom_line() +
  labs(title = "Apprehensions at the Border and Deportations, by Year")
```

So I decided to focus on just comparing apprehensions and deportations. 

```{r}
# Apprehensions vs Deportations
longdf_A_D_V %>% 
  filter(`Number of:`  %in% c("Apprehensions at the Border", "Deportations")) %>% 
  na.omit() %>% 
  mutate(year = as.integer(year))%>% 
  ggplot(aes(x = year, y = number, col = `Number of:`)) +
  geom_point() +
  geom_line() +
  labs(title = "Apprehensions at the Border and Deportations, by Year")
```

Deportations only filled less than half the years that apprehensions had data for, so I decided to filter for the years that had data for both apprehensions and deportations to 



```{r}
# Only years where there was both deportation and apphrehension data
app_vs_dep <- merge(apps_by_yr, icedeports_by_yr, all =  TRUE) %>% 
  arrange(year)
app_vs_dep

long_df_dep_app <- app_vs_dep %>% 
  filter(year > 2010) %>% 
    pivot_longer(cols = c("Apprehensions at the Border", "Deportations"),
                 names_to = "Number of:", names_transform = list(n = as.integer),
                 values_to = "number") %>% 
  na.omit()
long_df_dep_app

long_df_dep_app %>% 
  mutate(year = as.integer(year))%>% 
  ggplot(aes(x = year, y = number, col = `Number of:`)) +
  geom_point() +
  geom_line() +
  labs(title = "Apprehensions at the Border and Deportations, by Year")
```


Asides from the drop in both starting from 2019 and affecting a couple years beyond it, most likely due to the COVID 19 Pandemic, there did not seem to be any significant correlation/trend between apprehensions and deportations. Deportations seem to generally be trending downwards, and the same can be said for apprehensions in regards to its longer timeframe (2000-2022). However, in the shorter timeframe



#### 5.3.2.4 Border
```{r}
# Border vs Non-Border States Votes
long_df_bor %>% 
  filter(`Number of State Votes:` %in% c("Non-Border: Democrat", "Border: Democrat",
                        "Non-Border: Republican", "Border: Republican")) %>% 
  ggplot(aes(x = year, y = number, col = `Number of State Votes:`)) +
  geom_point() +
  geom_line() +
  scale_y_continuous(name="Number of Votes", labels = comma) +
  labs(title = "Border vs Non-Border State Votes, by Year", 
       y = "Number of Votes")
```


```{r}
# Border Differences
long_df_bor %>% 
  filter(`Number of State Votes:` %in% c("Border Vote Difference", "Non-Border Vote Difference")) %>% 
  ggplot(aes(x = year, y = number, col = `Number of State Votes:`)) +
  geom_point() +
  geom_line() +
  geom_hline(yintercept = 0, color = "black") +
  scale_y_continuous(name="Number of Votes", labels = comma) +
  labs(title = "Border vs Non-Border State Voting Difference (Rep - Dem), by Year", 
       y = "Number of Votes")
```
 
## 5.4 Research Question 3:

# 5.4.1 Data Sources

### 5.4.1.1 Sources of Data
In my research question, I'll be using two different dataset. The first one is from google trend which collects the public's query incidence score from 0-100 as the score goes up if the public searches more about immigration. The Google's trend dataset is coverage from 2000-2024.\n

[Google Trend](https://trends.google.com/trends/)\n

The second dataset I used is from US Custom and Border Protection as it gives us the apprhension data in the United State coveraged from 2020-2023 which shows the recent government enforcement.

[US Custom and Border](https://www.cbp.gov/document/stats/nationwide-encounters)

The US Custom and Border Protection dataset is collected by me and the Google Trend's data is collected by my groupmate Dowland.

### 5.4.1.2 Data Usage Permission

Both dataset is freely accessible to the public that have access to the internet. There are no restriction to the dataset. However for the Google Trend's data, you'll have to put the keyword in for example: "Immigration", to be able to search for the Query Incidence Score for the topic you're interested in.

### 5.4.1.3 Data Supporting Research Question

For my research question, I had chosen the Google Trend's dataset as it provide a measurable indicator of public interest in the topic of immigration across the time and regions. Since our research question focus on how public sentiment may influence immigration policy, the google trend's dataset will help us capture all the attention and concern of public in different election cycles.

The border Encounter data set (2020-2023) offers concrete data on immigration enforcement actions, such as apprehensions, expulsions and inadmissible cases. These action represent the policy outcomes we aim to evaluate in response to public sentiment. Together, these dataset will support my research question by allowing me to examine whether public interest are associate with changes in federal immigration enforcement.

## 5.4.2 Data

### 5.4.2.1 Google Trends Data
```{r}
google <- read.csv("../../data_cleaned/google_trends/summarized.csv")
head(google,3)
```
```{r}
str(google)
```
From the Google Trends Dataset, we can observe that there are 2730 columns and 4 rows of data. Which represent that there are 4 different measured variaible which are X (Number of observation), DMA (Designated Market Area), Datarange (the Date range of the data), and the query_incidence(Which is the score that represent the interset), with 2730 of different data (2730 columns).

```{r}
colSums(is.na(google))
```
When observing if there are any NA values in the Google trends data set, we can notice that there are 7 NA values in the Query_Incidence score variablees which will be removed for data cleaning.
```{r}
google <- google %>%
  filter(!is.na(query_incidence))
colSums(is.na(google))
```

### 5.4.2.2  Border Encounters Data

```{r}
apprehension <- read.csv("../../data_cleaned/sbo-encounters-fy20-fy23.csv")
head(apprehension,3)
```
```{r}
str(apprehension)
```
From Border Encounter's data set, we can observe that there are 2409 columns with 9 rows which tells us that there are 9 different variables which indicate the Fiscal Year, Month.Grouping, Month..abbv., ocponent(Which office), demographic, Citizenshipl.Grouping(Immigrant's Citizenship),Title of AUthroity, Encounter.Type (Inadmissibles, Expulsions, Apprehensions), and the Encounter.Count.
```{r}
colSums(is.na(apprehension))
```
By looking at the data below, there are no na value in the Apprehension data.



## 5.4.3 Method

### 5.4.3.1 Data Cleaninig for the Google Trends Data
```{r}
locales <- c("metro")
timeframes <- c("04-08", "08-12", "12-16", "16-20", "20-24", "16-17", "17-18", "18-19", "19-20", "20-21", "21-22", "22-23", "23-24")

read_imm_reg_timeframe <- function(region, daterange) {
  path <- str_c(
    "./data_cleaned/google_trends/query_immigration_",
    region,
    "_",
    daterange,
    "-election.csv"
  )

  df <- read.csv(path)

  df %>%
    mutate("daterange" = daterange) %>%
    (\(df) df %>% rename(query_incidence = names(df)[2]))() %>%
    select(DMA, daterange, query_incidence)
}
```
The original Google Trends data was spread across multiple CSV files, which each corresponding to a specific election cycle and region. Using a loop in R, we programmatically read, labeled, and combined these files into a single summary data set (summarized.csv), which contains the query incidence across the time of 2000-2024. 

* The Google Trends Data was cleaned by our groupmates Dowland which we all used the summarized.csv data as the main dataset for our google trend's data from 2004-2024

- The most relevent variables that will be answering our research question will be the daterange and the Query Incidence scores as we're able to observe the change of public interset over time through different election cycle in the United State.

#### Data Wrangling for Google Trends

```{r wrangle-data}
# Convert daterange to fiscal year for merge
google <- google %>%
  mutate(Fiscal.Year = case_when(
    daterange == "04-08" ~ 2008,
    daterange == "08-12" ~ 2012,
    daterange == "12-16" ~ 2016,
    daterange == "16-20" ~ 2020,
    daterange == "20-24" ~ 2024,
    TRUE ~ NA_real_
  ))

# Summarize public sentiment
google_summary <- google %>%
  group_by(Fiscal.Year) %>%
  summarise(avg_query_incidence = mean(query_incidence, na.rm = TRUE))

```
```{r}
google_merge <- google %>%
  mutate(Fiscal.Year = case_when(
    daterange == "16-20" ~ 2020,
    daterange == "20-21" ~ 2021,
    daterange == "21-22" ~ 2022,
    daterange == "22-23" ~ 2023,
    TRUE ~ NA_real_
  ))
google_mergesummary <- google_merge %>%
  group_by(Fiscal.Year) %>%
  summarise(avg_query_incidence = mean(query_incidence, na.rm = TRUE))
```


I transformed the Google Trends data by mapping each date range to a single fiscal year to align it with policy enforcement records. Then, I summarized public sentiment by calculating the average query incidence per year. Similarly, I grouped border enforcement data by fiscal year and encounter type, pivoting it into a wide format for easier comparison. These wrangling steps will allowed us to analyze both datasets on a same time scale, which would support our research in investigating the relationship between immigration sentiment and policy response.

To align the datasets for analysis, I created two separate summaries from the Google Trends data. The first, google_summary, includes all years from 2008 to 2024 and was used for analyzing long-term trends in public sentiment. The second, google_mergesummary, was filtered to include only the years from 2020 to 2023, in order to match the timeframe of the apprehension dataset. This separation ensures that when merging both datasets, only overlapping years are compared.

### 5.4.3.2 Data Cleaning for Border Encounters Data

```{r}
# Summarize enforcement data by year and type
app_summary <- apprehension %>%
  group_by(Fiscal.Year, Encounter.Type) %>%
  summarise(total = sum(Encounter.Count, na.rm = TRUE), .groups = "drop") %>%
  pivot_wider(names_from = Encounter.Type, values_from = total)
```


This is the data cleaning step where I organized the border encounter's data set. I grouped the dataset by Fiscal.Year and Encounter.Type to compute the total number of encounters for each type per year by summing encounter.count while removing any missing values. After that, I reshaped the data into a wide form so Encounter.Type became its own column with corresponding total count.

### 5.4.3.3 Merging Data
```{r}
combined_df <- left_join(google_mergesummary, app_summary, by = "Fiscal.Year")
head(combined_df,5)
```
To analyze the relationship between public sentiment and immigration enforcement, I merged the two cleaned summary datasets, Google Trends data and border encounter data using a left_join() on the shared variable Fiscal.Year as the google trends data set has been wrangled from date range to Fiscal Year. The merged summary data allowed me to combine the average search interest from Google Trends with the total number of apprehensions, expulsions, and inadmissible for each corresponding year.


# 6. Results

Results are presented in the respective research questions' sections above.

 i
## 6.2 RQ2: Results

I explored correlations visually (via line and scatter plots) and descriptively, and made adjustments for improved visual comparisons when appropriate (e.g. number scalings, filtering certain years, etc.)

Some of my key findings were:

- Election Trends: Democrats won the popular vote in most years between 2000â€“2020, but not always the presidency (e.g., 2000 and 2016).
```{r}
total_votes_by_yr %>% 
  mutate(year = as.character(year)) %>% 
  ggplot(aes(x = year, y = tot_votes)) +
  geom_col(aes(fill = party), stat = "identity", position = "dodge") +
  labs(title = "Election Results from Total Party Candidate Votes", 
       y = "Number of Candidate Votes")  +
   scale_y_continuous(name="Number of Candidate Votes", labels = comma) +
  scale_fill_manual(values = c("#03bfc4", "#f7766d"), 
                    breaks = c("DEMOCRAT", "REPUBLICAN"))

# Vote Difference Only
app_dep_votes %>%
  select(year, `Vote Difference (Republican minus Democrat)`) %>% 
  na.omit() %>% 
  # works, need the above 2 things to work
  ggplot(aes(x = year, y = `Vote Difference (Republican minus Democrat)`,
             color = `Vote Difference (Republican minus Democrat)`)) +
  geom_point(size = 2) +
  geom_line(aes(group=1)) + 
  geom_hline(yintercept = 0, color = "black") +
  scale_y_continuous(name="Number of Votes", labels = comma) +
  labs(title = "Voting Difference (Rep. - Dem.), by Year") +
  scale_color_gradient(labels = comma,
    low = "blue",
    high = "red")
```


- Deportation Trends: Deportations generally decreased from 2012â€“2023, with a sharp drop post-2019.

- Apprehensions: Sharp rise in 2019, coinciding with Trump administration raids, and a sharp drop during COVID.

```{r}
long_df_dep_app %>% 
  mutate(year = as.integer(year))%>% 
  ggplot(aes(x = year, y = number, col = `Number of:`)) +
  geom_point() +
  geom_line() +
  labs(title = "Apprehensions at the Border and Deportations, by Year")
```


- Border vs. Non-Border States: Voting patterns do not significantly differ between these groups and instead have very similar voting trends, contradicting assumptions that border states would lean more Republican.
```{r}
# Border vs Non-Border States Votes
long_df_bor %>% 
  filter(`Number of State Votes:` %in% c("Non-Border: Democrat", "Border: Democrat",
                        "Non-Border: Republican", "Border: Republican")) %>% 
  ggplot(aes(x = year, y = number, col = `Number of State Votes:`)) +
  geom_point() +
  geom_line() +
  scale_y_continuous(name="Number of Votes", labels = comma) +
  labs(title = "Border vs Non-Border State Votes, by Year", 
       y = "Number of Votes")

# Border Differences
long_df_bor %>% 
  filter(`Number of State Votes:` %in% c("Border Vote Difference", "Non-Border Vote Difference")) %>% 
  ggplot(aes(x = year, y = number, col = `Number of State Votes:`)) +
  geom_point() +
  geom_line() +
  geom_hline(yintercept = 0, color = "black") +
  scale_y_continuous(name="Number of Votes", labels = comma) +
  labs(title = "Border vs Non-Border State Voting Difference (Rep - Dem), by Year", 
       y = "Number of Votes")
```


These graphs illustrate that immigrant enforcement activity does not reliably or consistently track with party control.
 
## 6.3 RQ3: Results
(taken from section ## 5.4.3 Method)

### 6.3.1 Plot 1: Public Sentiment Over Time
```{r plot-sentiment}
ggplot(google_summary, aes(x = Fiscal.Year, y = avg_query_incidence)) +
  geom_line(color = "steelblue", size = 1.2) +
  labs(title = "Public Sentiment (Search Interest) Over Time",
       x = "Fiscal Year", y = "Average Search Index") +
  theme_minimal()
```
  This diagram shows the average Google Search interest in immigration across different years. From the data, we can observe that public attention peaked around 2012 and 2020, which aligns with the major election cycle of Obama and Trump. The trends have highlighted how immigration has become an important topic during the politically charged period but lost attention afterward.


### 6.3.2 Plot 2: Immigration Enforcement Over Time
```{r plot-enforcement}
app_long <- app_summary %>%
  pivot_longer(cols = c(Apprehensions, Expulsions, Inadmissibles),
               names_to = "Type", values_to = "Count")

ggplot(app_long, aes(x = Fiscal.Year, y = Count, color = Type)) +
  geom_line(size = 1.2) +
  labs(title = "Immigration Enforcement Encounters Over Time",
       x = "Fiscal Year", y = "Number of Encounters",
       color = "Enforcement Type") +
  scale_color_manual(values = c("Apprehensions" = "tomato",
                                "Expulsions" = "orange",
                                "Inadmissibles" = "purple")) +
  theme_minimal()
```

This line graph shows us the three different types of U.S Immigration enforcement action which include: Apprehensions, expulsions and inadmissible over the four fiscal years from 2020-2023. From the data, we can observe a rose in apprehension and has surpassed the rate of expulsion by 2022, which suggest a shift in enforcement strategy by the government. In additionaly, Inadmissble entris has also increased during this period, which indiccate a growing challenges at the broader for legal immigrant to enter.


### 6.3.3

```{r}
ggplot(combined_df, aes(x = avg_query_incidence, y = Apprehensions)) +
  geom_point(color = "tomato", size = 3) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    title = "Sentiment vs Apprehensions (2020â€“2023)",
    x = "Average Google Search Interest",
    y = "Number of Apprehensions"
  ) 

```
This scatterplot shows a clear negative correlation between average Google search interest in immigration and the number of apprehensions at the border. As public attention increases, enforcement activity appears to decline. This trend may suggest a lagged response in policy implementation or indicate that heightened public discourse influences shifts in enforcement priorities over time. 

### 6.3.4 Additional Analysis with Google Trends

```{r}
google%>%
  group_by(daterange) %>% 
  top_n(5,query_incidence)
```

The above code allows us to understand the top 5 quiery incidence scores with each daterange. Although some of the Designated Market Area is NA, however either the region or the city is provided.

```{r}
election_data <- google %>%
  filter(DMA %in% c("Miami-Ft. Lauderdale FL", "Yuma AZ-El Centro CA",
                    "Harlingen-Weslaco-Brownsville-McAllen TX", 
                    "Washington DC (Hagerstown MD)")) %>%
  filter(daterange %in% c("04-08", "08-12", "12-16", "16-20")) %>% # Filter for the desired date ranges
  mutate(election_year = case_when(
    daterange == "04-08" ~ "2004",
    daterange == "08-12" ~ "2008",
    daterange == "12-16" ~ "2012",
    daterange == "16-20" ~ "2016",
    TRUE ~ NA_character_
  ))

ggplot(election_data, aes(x = factor(election_year), y = query_incidence, color = DMA, group = DMA)) +
  geom_line() +
  geom_point(size = 3, shape = 21, fill = "white") +
  labs(title = "Immigration Search Trends Over Time", y = "Search Interest", x = "Election Year") +
  facet_wrap(~DMA)
```

This plots shows a diverse location of the immigration related google search interest across four different Distinct in the US. Notably, we can observe that Washington DC (Hagerstown, MD) has shows a steady rise in intersest, peaking in 2016, which reflect a increase in policy discouces in the nation's capital. In contrast, region like Yuma,AZ-El centro, CA has experience a sharp decline after 2004 to the topic of Immigration. This chats highlight how public sentiment around immigration is not uniform throughout the United State, where different region may put more attention on this topic than others.



# 7. Discussion

RQ1: Our analysis reveals that there is an increasingly strong correlation between search interest for immigration and the electoral swing in elections from 2004 - 2020 in the US.

RQ2: My analysis reveals that presidential election results do not appear to directly predict immigration enforcement activity. While Republican administrations are generally assumed to favor stricter immigration policy, actual deportation and apprehension figures vary year to year and are influenced by more than just electoral outcomesâ€”such as economic conditions, global migration patterns, or events like COVID-19. The spike in apprehensions and deportations in 2019 is a clear outlier likely driven by targeted ICE activity and publicized raids. The COVID-19 pandemic appears to have curtailed migration and enforcement alike, given the decrease in both apprehensions and deporations.

TODO:
Conclusions:
- Popular vote election results was not a good predictor of deportations and apprehensions, no discernable trend even at a glance

- Spike in 2019 when ICE Raids were carried out under President Donald Trump

- COVID 19 in 2019 significantly drove down border encounters and deportations

- Border states did not seem to significantly vote more Republican than Democrat, thereby not having a great impact on election results 

RQ3: From my research, I had notice a negative relationship between the search interest in immigration and immigration apprehension which is what I didn't expect at the start. Specifically, from the period of 2020-2023, an decrease in the search interest has cause the apprehension encounters to increase over the 4 years which was what our team wasn't expecting. This impliies that rising attention or conern is not promptly associated with an increase in enforcement. However, this negative relationship may be cause by a possibility of policy lag or time lags when government is enforcing a change in their policy. Government are likely not going to immediately react or make a change in policy when they notice an increase in public sentiment with Immigration topic. It will take times for the government to make a change in policy, or actually do something to the public about it.

In conclusion, our research about the relationship with public sentiment and policy change has suggest that public sentiment about immigration may be connected to the shift in immigration enforcement, particulary around 2012 to 2020. The observed patterns and relationship may imply that a increased in public attention could coontribute to shaping federal responses and changes in the future, although factors like time lags may exist. In addition, the regional Google Trend's data also show how the conern about immigration is not uniform across the United State where some region have higher attention about the topic.

Together, these results support the idea that immigration enforcement is shaped not only by the government's plan, but also by social dynamics as well, including media attention, public discourse, and regional pressures.

## 7.2 Limitations

RQ1: Of note, our chosen metric of public opinion on immigration measures only frequency, not directionality (like/dislike). Furthermore, we have no mechanism for establishing a causal relationship between search interest and election results, due to confounding variables (most voters are presumably not single-issue voters).

RQ2: Limitations:
- Data years do not align perfectly across datasets.

- Some relevant events (e.g., Title 42 expulsions, sanctuary policies) are not captured.

- Research Question does not try to tackle causation, only attempting to find potential trends and associations.

RQ3: Through out my research, I had notice some limitation about my research and anaylis:

* Google Trends measures attention, not opinion. A rise in search volume may indicate growing public interest in immigration, but it doesnâ€™t tell us whether that interest is positive or negative.

* The data captures search behavior, not direct public action such as voting, protesting, or advocating for immigration reform.

* Regional Google Trends data is based on relative scores (0â€“100), not absolute search volume, which makes it difficult to compare true magnitude across locations.

* The possibility of Time Lag from the goverment's enforcement may cause the result to become what we're not expecting. For example, time lag may have switched a positive relationship between public sentiment and apprehension encoutners into a negative relationsihp.

## 7.3 Future Work

RQ1: It may be helpful to establish a wider dataset incorporating search terms which reveal an individual's attitude towards immigrants. For example, search terms like, "illegal alien," "gang member," "MS-13," and others may provide helpful context. It may also be worth comparing search interest for immigration with other topics relevant to elections in the US (e.g., "deficit spending," "China," etc.). This expanded dataset could aid in establishing a more direct causal link between search interest and electoral outcomes.

RQ2: In regards to future research, perhaps zooming in on more specific states and their voting patterns and comparing voting patterns between states and/or counties specifically bordering on Mexico, Canada, or not would be more insightful in seeing if there are trends/patterns regarding immigration there. Other, more focused and complete datasets for deportation or policy could be used, and comparisons/analysis regarding specific and more concrete immigration/border policies could be addressed. 

RQ3: For my future research, I wish I could incorporate sentiment analysis from social media or news articles to capture actual actions, not just attention. In addition, I would like to expand the enforcement dataset to include more years which would  improve our longitudinal analysis. 


# 8. Summary

RQ1: We establish a correlation between search interest for immigration and electoral swings in the US. Furthermore, 

RQ2: While electoral results offer political context, they are not strong predictors of immigration enforcement trends. Policymakers and analysts should consider broader factors, including administrative policy, global crises, and migration flows, when interpreting enforcement changes. The findings of this research question suggest that the real-world outcomes of immigration policy are not solely determined by who wins the presidency and which party they belong to, and that whether or not a state is on the borders of the United States does not necessarily lead them to vote more Republican in favor of harsher immigration policies.

RQ3: 
In summary, this research highlights a potentional reltaionship between public centiment and immigration enforcement in the US as a increase in public sentiment will later on cause the government to improve and enforce immigration policy that is fair to everyone. While the relationship between public centiment and government's enforcement may not be specific (Negative relationship between both variables), we can still interpret that the public's interest still plays a huge role in government's policy change.
